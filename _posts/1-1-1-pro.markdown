---
layout: default
img: 1-1-1-pro.png
category: Projects
title: Deep Bi-Modal Representations to discriminate User Likes
description: |
---

Automatically understanding and discriminating different users' liking for an image is a challenging problem. This is because the relationship between image features (even semantic ones extracted by existing tools, viz. faces, objects, etc.) and users' likes is non-linear, influenced by several subtle factors.   

  * This work presents a deep bi-modal knowledge representation of images based on their visual content and associated tags (text). A mapping step between the different levels of visual and textual representations allows for the transfer of semantic knowledge between the two modalities.   

  * Feature selection is applied before learning deep representation to identify the important features for a user to like an image.    
  
  * The proposed representation is shown to be effective in discriminating users based on images they like and also in recommending images that a given user 'likes', outperforming state-of-the-art feature representations by around 15-20%.    
  
  * Beyond this test-set performance, an attempt is made to qualitatively understand the representations learned by the deep architecture used to model user `likes'.   
  
Publications:
  + **S.C.Guntuku**, J. T. Zhou, S. Roy, W. Lin, I. W. Tsang, **_Understanding Deep Representations Learned in Modeling User Likes_**, IEEE Transactions on Image Processing, 2016, [PDF] (https://www.dropbox.com/s/iwnhq1w3m3i70nd/TIP_SubmissionR3.pdf?dl=1)    
  + **S.C.Guntuku**, S. Roy, W. Lin, **_Evaluating Visual and Textual Features for Modeling User Likes_**, IEEE ICME,  2015. [PDF] (https://www.dropbox.com/s/43xkoqui4liac1j/ICME2015_ID114.pdf?dl=1)  
  + **S.C.Guntuku**, J. T. Zhou, S. Roy, W. Lin, I. W. Tsang,  **_Deep Representations to Model User Likes_**, 12th Asian Conference on Computer Vision, 2014, Oral [PDF] (https://www.dropbox.com/s/cjjxt1cqw7wdqtk/ACCV2014.pdf?dl=1)  

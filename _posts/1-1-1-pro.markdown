---
layout: default
img: 1-1-1-pro.png
category: Projects
title: Deep Bi-Modal Representations to discriminate User Likes
description: |
---

Automatically understanding and discriminating different users' liking for an image is a challenging problem. This is because the relationship between image features (even semantic ones extracted by existing tools, viz. faces, objects, etc.) and users' likes is non-linear, influenced by several subtle factors.   

  * This work presents a deep bi-modal knowledge representation of images based on their visual content and associated tags (text). A mapping step between the different levels of visual and textual representations allows for the transfer of semantic knowledge between the two modalities.   

  * Feature selection is applied before learning deep representation to identify the important features for a user to like an image.    
  
  * The proposed representation is shown to be effective in discriminating users based on images they like and also in recommending images that a given user 'likes', outperforming state-of-the-art feature representations by around 15-20%.    
  
  * Beyond this test-set performance, an attempt is made to qualitatively understand the representations learned by the deep architecture used to model user `likes'.   
  
Publications:   

 +  **S.C.Guntuku**, J. T. Zhou, S. Roy, W. Lin, I. W. Tsang, **_Understanding Deep Representations Learned in Modeling User Likes_**, IEEE Transactions on Image Processing, 2016, [PDF preprint](https://www.researchgate.net/publication/303498119_Understanding_Deep_Representations_Learned_in_Modeling_Users_Likes%27)  

 +  **S.C.Guntuku**, S. Roy, W. Lin, **_Evaluating Visual and Textual Features for Modeling User Likes_**, IEEE ICME,  2015. [PDF](https://www.researchgate.net/publication/281642949_Evaluating_visual_and_textual_features_for_predicting_user_%27likes%27)    

 + **S.C.Guntuku**, J. T. Zhou, S. Roy, W. Lin, I. W. Tsang,  **_Deep Representations to Model User Likes_**, 12th Asian Conference on Computer Vision, 2014, Oral [PDF](https://www.researchgate.net/publication/281642951_Deep_Representations_to_Model_User_%27Likes%27)   
